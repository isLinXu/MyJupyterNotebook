{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ikzIVWRna_Cq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ZL2MBjU2T1V"
   },
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DH5Eniyh2eU0"
   },
   "outputs": [],
   "source": [
    "class inceptionv1_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels1, out_channels2_step1, out_channels2_step2, out_channels3_step1, out_channels3_step2, out_channels4):\n",
    "        super(inceptionv1_block, self).__init__()\n",
    "        self.branch1_conv = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels1, kernel_size=1),\n",
    "                          nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.branch2_conv1 = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels2_step1, kernel_size=1),\n",
    "                          nn.ReLU(inplace=True))\n",
    "        self.branch2_conv2 = nn.Sequential(nn.Conv2d(in_channels=out_channels2_step1, out_channels=out_channels2_step2, kernel_size=3, padding=1),\n",
    "                          nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.branch3_conv1 = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels3_step1, kernel_size=1),\n",
    "                          nn.ReLU(inplace=True))\n",
    "        self.branch3_conv2 = nn.Sequential(nn.Conv2d(in_channels=out_channels3_step1, out_channels=out_channels3_step2, kernel_size=5, padding=2),\n",
    "                          nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.branch4_maxpooling = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.branch4_conv1 = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels4, kernel_size=1),\n",
    "                          nn.ReLU(inplace=True))\n",
    "     \n",
    "    def forward(self, x):\n",
    "        out1 = self.branch1_conv(x)\n",
    "        out2 = self.branch2_conv2(self.branch2_conv1(x))\n",
    "        out3 = self.branch3_conv2(self.branch3_conv1(x))\n",
    "        out4 = self.branch4_conv1(self.branch4_maxpooling(x))\n",
    "        out = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HPJCGTmA2eZT"
   },
   "outputs": [],
   "source": [
    "class auxiliary_classifiers(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(auxiliary_classifiers, self).__init__()\n",
    "        self.avgpooling = nn.AvgPool2d(kernel_size=5, stride=3)\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=128, kernel_size=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=128*4*4, out_features=1024)\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=1024, out_features=out_channels)\n",
    "     \n",
    "    def forward(self, x):\n",
    "        x = self.avgpooling(x)\n",
    "        x = F.relu(self.conv(x))\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=0.5)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kx6yCzU6paEn"
   },
   "outputs": [],
   "source": [
    "class InceptionV1(nn.Module):\n",
    "    def __init__(self, num_classes, training=True):\n",
    "        super(InceptionV1, self).__init__()\n",
    "        self.training = training\n",
    "        self.conv = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3),\n",
    "                      nn.ReLU(inplace=True),\n",
    "                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "                      nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1),\n",
    "                      nn.ReLU(inplace=True),\n",
    "                      nn.Conv2d(in_channels=64, out_channels=192, kernel_size=3, stride=1, padding=1),\n",
    "                      nn.ReLU(inplace=True),\n",
    "                      nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "        \n",
    "        self.inception1 = inceptionv1_block(in_channels=192, out_channels1=64, out_channels2_step1=96, out_channels2_step2=128, out_channels3_step1=16, out_channels3_step2=32, out_channels4=32)\n",
    "        self.inception2 = inceptionv1_block(in_channels=256, out_channels1=128, out_channels2_step1=128, out_channels2_step2=192, out_channels3_step1=32, out_channels3_step2=96, out_channels4=64)\n",
    "        self.maxpooling1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception3 = inceptionv1_block(in_channels=480, out_channels1=192, out_channels2_step1=96, out_channels2_step2=208, out_channels3_step1=16, out_channels3_step2=48, out_channels4=64)\n",
    "\n",
    "        if self.training == True:\n",
    "            self.auxiliary1 = auxiliary_classifiers(in_channels=512,out_channels=num_classes)\n",
    "\n",
    "        self.inception4 = inceptionv1_block(in_channels=512 ,out_channels1=160, out_channels2_step1=112, out_channels2_step2=224, out_channels3_step1=24, out_channels3_step2=64, out_channels4=64)\n",
    "        self.inception5 = inceptionv1_block(in_channels=512, out_channels1=128, out_channels2_step1=128, out_channels2_step2=256, out_channels3_step1=24, out_channels3_step2=64, out_channels4=64)\n",
    "        self.inception6 = inceptionv1_block(in_channels=512, out_channels1=112, out_channels2_step1=144, out_channels2_step2=288, out_channels3_step1=32, out_channels3_step2=64, out_channels4=64)\n",
    "\n",
    "        if self.training == True:\n",
    "            self.auxiliary2 = auxiliary_classifiers(in_channels=528,out_channels=num_classes)\n",
    "\n",
    "        self.inception7 = inceptionv1_block(in_channels=528, out_channels1=256, out_channels2_step1=160, out_channels2_step2=320, out_channels3_step1=32, out_channels3_step2=128, out_channels4=128)\n",
    "        self.maxpooling2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.inception8 = inceptionv1_block(in_channels=832, out_channels1=256, out_channels2_step1=160, out_channels2_step2=320, out_channels3_step1=32, out_channels3_step2=128, out_channels4=128)\n",
    "        self.inception9 = inceptionv1_block(in_channels=832, out_channels1=384, out_channels2_step1=192, out_channels2_step2=384, out_channels3_step1=48, out_channels3_step2=128, out_channels4=128)\n",
    "\n",
    "        self.avgpooling = nn.AvgPool2d(kernel_size=7,stride=1)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc = nn.Linear(in_features=1024,out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.inception1(x)\n",
    "        x = self.inception2(x)\n",
    "        x = self.maxpooling1(x)\n",
    "        x = self.inception3(x)\n",
    "        aux1 = self.auxiliary1(x)\n",
    "        x = self.inception4(x)\n",
    "        x = self.inception5(x)\n",
    "        x = self.inception6(x)\n",
    "        aux2 = self.auxiliary2(x)\n",
    "        x = self.inception7(x)\n",
    "        x = self.maxpooling2(x)\n",
    "        x = self.inception8(x)\n",
    "        x = self.inception9(x)\n",
    "        x = self.avgpooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        out = self.fc(x)\n",
    "\n",
    "        if self.training == True:\n",
    "            return aux1, aux2, out\n",
    "\n",
    "        else:\n",
    "            return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cvVoVaeWpaMW"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "num_classes=2\n",
    "model = InceptionV1(2, training=True)\n",
    "\n",
    "if CUDA:\n",
    "    model = model.cuda()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uW2ixXvxpaPG"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# kaggle api\n",
    "api_token = {\"username\":\"aaa\",\"key\":\"kkk\"}\n",
    " \n",
    "if not os.path.exists(\"/root/.kaggle\"):\n",
    "    os.makedirs(\"/root/.kaggle\")\n",
    "\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    " \n",
    "if not os.path.exists(\"/kaggle\"):\n",
    "    os.makedirs(\"/kaggle\")\n",
    "os.chdir('/kaggle')\n",
    "!kaggle datasets download -d chetankv/dogs-cats-images --force\n",
    " \n",
    "!ls /kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fLBxoQ413vu8"
   },
   "outputs": [],
   "source": [
    "!unzip dogs-cats-images.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wly0Gj1f3vxT"
   },
   "outputs": [],
   "source": [
    "# Transform\n",
    "transform = transforms.Compose(\n",
    "                [transforms.Resize(size=(227,227)),\n",
    "                 transforms.CenterCrop(224),\n",
    "                 transforms.RandomRotation(20),\n",
    "                  transforms.RandomHorizontalFlip(),\n",
    "                 transforms.ToTensor(),\n",
    "                transforms.Normalize((0.5,), (0.5,)),]\n",
    "                )\n",
    "\n",
    "# Data\n",
    "train_dataset = datasets.ImageFolder(root='/kaggle/dataset/training_set', transform=transform)\n",
    "valid_dataset = datasets.ImageFolder(root='/kaggle/dataset/test_set', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfLflX5f3vzy"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    model.train()\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target) \n",
    "        \n",
    "        if CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        # clear gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagation\n",
    "        output, aux1, aux2 = model(data) \n",
    "        loss_output = criterion(output, target) \n",
    "        loss_aux1 = criterion(aux1, target) \n",
    "        loss_aux2 = criterion(aux2, target) \n",
    "        loss = loss_output + loss_aux1 * 0.3 + loss_aux2 * 0.3\n",
    "\n",
    "        # Calculate gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        total_train += len(target)\n",
    "        correct_train += sum((predicted == target).float())\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\"Train Epoch: {}/{} [iter： {}/{}], acc： {:.6f}, loss： {:.6f}\".format(\n",
    "               epoch+1, num_epochs, batch_idx+1, len(train_loader),\n",
    "               correct_train / float((batch_idx + 1) * batch_size),\n",
    "               train_loss / float((batch_idx + 1) * batch_size)))\n",
    "            \n",
    "    train_acc_ = 100 * (correct_train / float(total_train))\n",
    "    train_loss_ = train_loss / total_train\n",
    "                    \n",
    "    return train_acc_, train_loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ji_uE-hK3060"
   },
   "outputs": [],
   "source": [
    "def validate(valid_loader, model, criterion, epoch): \n",
    "    model.eval()\n",
    "    total_valid = 0\n",
    "    correct_valid = 0\n",
    "    valid_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "        data, target = Variable(data), Variable(target) \n",
    "        \n",
    "        if CUDA:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target) \n",
    "\n",
    "        predicted = torch.max(output.data, 1)[1]\n",
    "        total_valid += len(target)\n",
    "        correct_valid += sum((predicted == target).float())\n",
    "        valid_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\"Valid Epoch: {}/{} [iter： {}/{}], acc： {:.6f}, loss： {:.6f}\".format(\n",
    "               epoch+1, num_epochs, batch_idx+1, len(valid_loader),\n",
    "               correct_valid / float((batch_idx + 1) * batch_size),\n",
    "               valid_loss / float((batch_idx + 1) * batch_size)))\n",
    "            \n",
    "    valid_acc_ = 100 * (correct_valid / float(total_valid))\n",
    "    valid_loss_ = valid_loss / total_valid\n",
    "                    \n",
    "    return valid_acc_, valid_loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ph-MACjR3087"
   },
   "outputs": [],
   "source": [
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader):\n",
    "    # set objects for storing metrics\n",
    "    total_train_loss = []\n",
    "    total_valid_loss = []\n",
    "    total_train_accuracy = []\n",
    "    total_valid_accuracy = []\n",
    " \n",
    "    # Train model\n",
    "    for epoch in range(num_epochs):\n",
    "        # training\n",
    "        train_acc_, train_loss_ = train(train_loader, model, criterion, optimizer, epoch)\n",
    "        total_train_loss.append(train_loss_)\n",
    "        total_train_accuracy.append(train_acc_)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            valid_acc_, valid_loss_ = validate(valid_loader, model, criterion, epoch)\n",
    "            total_valid_loss.append(valid_loss_)\n",
    "            total_valid_accuracy.append(valid_acc_)\n",
    "\n",
    "        print('==========================================================================')\n",
    "        print(\"Epoch: {}/{}， Train acc： {:.6f}， Train loss： {:.6f}， Valid acc： {:.6f}， Valid loss： {:.6f}\".format(\n",
    "               epoch+1, num_epochs, \n",
    "               train_acc_, train_loss_,\n",
    "               valid_acc_, valid_loss_))\n",
    "        print('==========================================================================')\n",
    "\n",
    "    print(\"====== END ==========\")\n",
    "\n",
    "    return total_train_loss, total_valid_loss, total_train_accuracy, total_valid_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_nGbEbgO3v2z"
   },
   "outputs": [],
   "source": [
    "total_train_loss, total_valid_loss, total_train_accuracy, total_valid_accuracy = training_loop(model, criterion, optimizer, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfmFEWzGpaRO"
   },
   "outputs": [],
   "source": [
    "def plot_result(total_train, total_valid, label):\n",
    "    plt.plot(range(num_epochs), total_train, 'b-', label=f'Training_{label}')\n",
    "    plt.plot(range(num_epochs), total_valid, 'g-', label=f'validation_{label}')\n",
    "    plt.title(f'Training & Validation {label}')\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel(f'{label}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8E0RhBgT35is"
   },
   "outputs": [],
   "source": [
    "plot_result(total_train_loss, total_valid_loss, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RwmduxQi35ms"
   },
   "outputs": [],
   "source": [
    "plot_result(total_train_accuracy, total_valid_accuracy, 'accuracy')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNay6WH/v5dNgKtxAZFLBe+",
   "collapsed_sections": [],
   "name": "InceptionV1.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
